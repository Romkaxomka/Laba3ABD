{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3Laba",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtzqvHVMG2jdAyivFJ4ovF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romkaxomka/Laba3ABD/blob/main/4Laba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adpM8WEHt82C"
      },
      "source": [
        "#Часть 1.\n",
        "#Выполнить парсинг вакансий любого рекрутингового сайта (HeadHunter, Indeed, SuperJob, Зарплата, и тд) с фильтром по отрасли ИТ.\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        " \n",
        "  \n",
        "def getPage(page = 0):\n",
        "  params = {\n",
        "      'area': 95, # Поиск ощуществляется по вакансиям города Москва\n",
        "      'page': page, # Индекс страницы поиска на HH\n",
        "      'per_page': 100 # Кол-во вакансий на 1 странице\n",
        "  }\n",
        "\n",
        "  req = requests.get('https://api.hh.ru/vacancies', params)\n",
        "  data = req.content.decode()\n",
        "  req.close()\n",
        "  return data\n",
        " \n",
        "f = open('vacancies.csv', mode='w', encoding='utf8')\n",
        "writer = csv.writer(f)\n",
        "\n",
        "headers = [\"name\", \"area\", \"salary_from\", \"salary_to\", \"employer_name\", \"published_at\", \"schedule\", \"responsibility\", \"requirement\"]\n",
        "writer.writerow(headers)\n",
        "\n",
        "for page in range(0, 20):\n",
        "  jsObj = json.loads(getPage(page))\n",
        "\n",
        "  for item in jsObj['items']:\n",
        "    obj_to_write = []\n",
        "\n",
        "    obj_to_write.append(item['name'])\n",
        "\n",
        "    obj_to_write.append(item['area']['name'])\n",
        "\n",
        "    if not item['salary'] is None:\n",
        "      obj_to_write.append(item['salary']['from'])\n",
        "      obj_to_write.append(item['salary']['to'])\n",
        "    else:\n",
        "      obj_to_write.append(None)\n",
        "      obj_to_write.append(None)\n",
        "\n",
        "    obj_to_write.append(item['employer']['name'])\n",
        "    \n",
        "    obj_to_write.append(item['published_at'])\n",
        "\n",
        "    obj_to_write.append(item['schedule']['name'])\n",
        "\n",
        "    obj_to_write.append(item['snippet']['responsibility'])\n",
        "    obj_to_write.append(item['snippet']['requirement'])\n",
        "\n",
        "    writer.writerow(obj_to_write)\n",
        "\n",
        "  if (jsObj['pages'] - page) <= 1:\n",
        "    break\n",
        "  time.sleep(0.25)\n",
        "\n",
        "\n",
        "f.close()\n",
        "print('Старницы поиска собраны')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEmGZuS43Ev9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('vacancies.csv')\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jqFjyjE4T8Q"
      },
      "source": [
        "# Часть 2.\n",
        "# Проведение первичного анализа сформированного датасета.\n",
        "# 1) Выполнить двойную сортировку вакансий: сначала по значению максимальной зарплаты, затем по значению минимальной зарплаты.\n",
        "\n",
        "df = df.sort_values(by='salary_from')\n",
        "df = df.sort_values(by='salary_to')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MIpD2TprVYo"
      },
      "source": [
        "# 2) Разделить отсортированный датасет на 10 групп по значению максимальной зарплаты.\n",
        "sort_groups = np.array_split(df, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99T7GuUXrXKs"
      },
      "source": [
        "# 3) Посчитать для каждой группы:\n",
        "def count_by_atr(atribute):\n",
        "  for i in range(10):\n",
        "    print('\\nGroup #' + str(i+1) + ':')\n",
        "    print(sort_groups[i][atribute].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2veJMuXuIZT"
      },
      "source": [
        "# a) все возможные названия вакансий и количество вхождений каждой из них в группу;\n",
        "count_by_atr('name')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EYRRuhCrYgW"
      },
      "source": [
        "# b) среднее, максимальное и минимальное количество дней, на протяжении которых размещена вакансия на сайте (от даты парсинга);\n",
        "from datetime import datetime, date, timedelta\n",
        "\n",
        "def dates_check():\n",
        "  for i in range(10):\n",
        "    a = 0\n",
        "    datesArr = []\n",
        "    print('\\nGroup #' + str(i+1))\n",
        "    while a < len(sort_groups[i]['published_at']):\n",
        "      datesArr.append(abs(datetime.now()-datetime.strptime(sort_groups[i]['published_at'].values[a][:10], \"%Y-%m-%d\")).days)\n",
        "      a = a +1\n",
        "    print('\\tМинимальное количество дней:', min(datesArr))\n",
        "    print('\\tСреднее количество дней:', sum(datesArr)/len(datesArr))\n",
        "    print('\\tМаксимальное количество дней:', max(datesArr))\n",
        "\n",
        "dates_check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcaFOwd5twd7"
      },
      "source": [
        "# c) все возможные значения требуемого опыта работы и количество вхождений каждого из них в группу;\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ws9nzsQrZw0"
      },
      "source": [
        "# d) все возможные значения типов занятости и количество вхождений каждого из них в группу;\n",
        "count_by_atr('schedule')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW7C4MS2t0a2"
      },
      "source": [
        "# e) все возможные значения рабочего графика и количество вхождений каждого из них в группу;\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW0Z1QZat2Pa"
      },
      "source": [
        "# f) набор уникальных ключевых навыков и количество вхождений каждого навыка в группу.\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2NX5k_Zra-A"
      },
      "source": [
        "#Часть 3.\n",
        "#Разделить отсортированный датасет на группы по значению названия вакансии. \n",
        "df = df.sort_values(by='name')\n",
        "sort_groups = np.array_split(df, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSTe-Ikgrb_B"
      },
      "source": [
        "#Посчитать для каждой группы:\n",
        "#1) все возможные значения максимальной и минимальной зарплаты и количество вхождений каждой из них в группу;\n",
        "count_by_atr('salary_from')\n",
        "count_by_atr('salary_to')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtVErtvrdUP"
      },
      "source": [
        "#2) среднее, максимальное и минимальное количество дней, на протяжении которых размещена вакансия на сайте (от даты парсинга);\n",
        "dates_check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m1fONgwt7Za"
      },
      "source": [
        "#3) все возможные значения требуемого опыта работы и количество вхождений каждого из них в группу;\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReB3sWQbreR8"
      },
      "source": [
        "#4) все возможные значения типов занятости и количество вхождений каждого из них в группу;\n",
        "count_by_atr('schedule')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XtfbkVCt-nU"
      },
      "source": [
        "#5) все возможные значения рабочего графика и количество вхождений каждого из них в группу;\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4NifCvuuAm4"
      },
      "source": [
        "#6) набор уникальных ключевых навыков и количество вхождений каждого навыка в группу.\n",
        "# Не смог выгрузить"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}